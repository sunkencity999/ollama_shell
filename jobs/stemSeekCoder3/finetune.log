Starting fine-tuning of deepseek-coder-v2:16b
Parameters: batch_size=2, learning_rate=0.0002
Dataset: jobs/stemSeekCoder3/mlx_dataset/train.jsonl

MLX is properly installed
Found finetune script in app root: /Users/christopher.bradford/ollamaShell/finetune.py
Running command: /Users/christopher.bradford/ollamaShell/venv/bin/python /Users/christopher.bradford/ollamaShell/finetune.py --model deepseek-coder-v2:16b --train-file jobs/stemSeekCoder3/mlx_dataset/train.jsonl --ollama --batch-size 2 --learning-rate 0.0002 --max-steps 100 --save-every 10 --output-dir jobs/stemSeekCoder3/output


Training complete!
Model saved to jobs/stemSeekCoder3/output
